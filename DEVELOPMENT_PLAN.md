I want to make an app that can help facilitate a participatory phonology analysis process of native speakers comparing words and grouping them with words of similar tone melodies. The process works like this:

1. Separate words by grammatical categories and consonant/vowel syllable profiles (for example don't compare CCVCV nouns with VCV nouns, or verbs with nouns, compare CVCV nouns with CVCV nouns and then compare VCV nouns with other VCV nouns, etc).
2. For each group of words with the same syllable profile and grammatical category, the native speaker goes through the words one at a time. The first word becomes the exemplar for the first surface tone melody (for example if the first word is "parrot", then it becomes the first word in the "parrot-like-tone" groups).
3. Each successive word is compared one at a time with each category to see if the tone sounds the same. If it does, put it in that category, if it doesn't, keep comparing tone-melody groups one at a time until you find one that fits, OR you can create a new group with the current word as the exemplar.
4. For each exemplar, you draw a picture at the top of a page. That picture will be a memory aid to remember that particular tone melody.
5. Periodically, after each page has a lot of examples (like every time 20 more have been added to a particular tone group), stop and listen to and compare all the words in the tone group. Then decide if you want to to select any of them as outliers (to kick out of the group). Also if you decide several of them sound like each other, but not like the rest of the group, you can group those together as similar to each other. Then you decide for each word (or set of words) that doesn't actually fit whether to put it/them in another group or create yet another new one.

6. Do this until you've worked through all the words in the current grammatical category/syllable-profile group of words.

Here's how I'm envisioning my app working:
1. Use Dart/Flutter for the Android (and Desktop, make it work for both, for Android and for Windows) app and use Node.JS/Electron for the companion Desktop App (which configures the bundle for the app to use).
2. The Desktop app creates a zip file bundle for the Android App to work with. Each bundle should consist of the following:
--A Dekereke XML file that the user selects (UTF-16 format, make sure in no way to let our app change or modify the XML declaration), root element <phon_data>, row/record elements <data_form>, let the user on the desktop specify which daughter of data_form will contain the text to display for the word (or whether it will display anything at all, the user can decide whether to show or hide text). Each record contains a <SoundFile> element that specifies the base filename for a 16-bit (or 24-bit) wav sound file associated with the record.
--A settings file for our app that will have user settings that the user chose in the Desktop app. These settings include:
	----Which daughter of <data_form> to choose for the written form of the word that will display (with a show/hide written form checkbox). Actually they can select multiple daughters of <phon_data> to be written forms if they want (for example phonetic, phonemic, orthographic, or orthographic + tone). But it should default to only one, and <Phonetic>
	----Whether to add a suffix to the soundfile from the <SoundFile> element, and which suffix (so for example if the SoundFile element contains 001_stand.up.wav and the user defines the suffix "-phon", then the app will use "001_stand.up.wav") as the sound file for that record.
	----Reference numbers (separated by commas, spaces, or new lines, or a mix of these) for which records the app will display/play (these match the data_form/Reference element).
	----A setting for whether or not the user should type in their own spelling of each word before moving on (and also which daughter element of data_form to store that in). Default to "Orthogrphic"
	----The name of the daughter elemnt of <data_form> to put the tone group assignment in (that the user will create in the app). Defaul to "SurfaceMelodyGroup"
	----an audio folder containing the associated wav files that the user selects. Our bundler app should ONLY include wav files that match sound files in records matching reference numbers we've selected and the suffix we defined (or just the base sound file if we didn't define a suffix). Warn the user about any sound files you couldn't find.

3. The Android app loads the bundle and then with a VERY simple, entirely graphical (buttons, icons, images, not words) UI, very carefully walk the user through the process above. First, play the first word in the list. Let them play it as many times as they want. Then the user draws a picture on a piece of paper and takes a picture of it. That becomes the picture for the first tone-melody-category. Then there's a checkbox for when they're done. If the Desktop bundler user checked this setting, require the user to type in their own spelling of each word before moving on (that way they'll see the exemplar picture and a list of written words for every category. That list should use the first "written form" daughter unless and until the native speaker has keyed in their own spelling, at which point each entry should use that if it exists).
4. One screen, one word at a time, they can compare it with all the tone groups (represented by pictures) and play audio for every word that is in that group so far, or swipe back and forward between groups, or create a new one (and take a picture of the drawing). They can do this until they're satisfied they've found the right group to put the current word in and then when they confirm that, they can move on to the next word. Each new tone group gets a number (starting with 1) and that gets put in the element the user defined in the Desktop bundler app.
This they do until they've gone through all the words and then they can export the results back to the field researcher who built the bundle. The results should be a zip file containing the following:
	--the XML file they had before but now including the changes made by the app (text typed in by the user in the appropriate element, tone group numbers in the appropriate element, MAKE SURE the exact character encoding and XML declaration that was there at the start is there at the end so that Phonology Database app that generated the XML file can still read it). 
	--a CSV file with column headers listing tone group numbers, exemplar words (with the Reference number and the first "written form" for each), and picture file names for the photo of the drawing
	--the photos the user took for their exemplar words

5. Eventually we'd like a desktop app that can import the results from multiple native speakers who had the app on their phone and worked on the same set of words and compare the categories they came up with. They might not (and even likely will not) necessarily have the same exemplar word or number, but there should be very substantial overlap in tone group membership and our comparison app should be able to reconstruct the groups and flag and point out words that seemed to generate disagreement between the different users (i.e. they grouped them differently) and also list the exemplars and pictures that might be multiple possibilities for the same tne group (for example if two different users had the same tone group but one chose "lizard" for the exemplar and another chose "snake", point that out so that the researcher can ask them which is better to use moving forward).

6. Basically this whole process only does one grammatical category and syllable pattern at a time. It's up to the researcher to build different bundles for each successive grammatical category and syllable pattern. They can use the Dekereke app to sort by category, CVCV word shape, etc, and then copy the reference numbers from Dekereke into our app. Our app then only shows records matching reference numbers (but saves the whole XML file) and only imports audio files that match the reference number and SoundFile and suffix (optional). Every time it imports a new bundle, it erases existing data to save space before importing the new bundle.